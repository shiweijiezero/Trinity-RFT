\begin{figure}[t]
\centering
\begin{minipage}[t]{1\linewidth}
\centering
\includegraphics[width=1.0\textwidth]{figure/src/attention_visual.pdf}
\end{minipage}
\centering
\caption{The visualization of QPI's attention weights in HC-LLM, where the heatmap shows the attention weights between questions and passages across model layers. The x-axis corresponds to the passages and question serving as attention keys/values, while the y-axis indexes the HC-LLM layers. A darker color indicates a larger attention weight. In this case, $p_5$ and $p_{13}$ contain answer evidence and receive higher weighting, while the irrelevant passages receive lower attention weights. This demonstrates how the question-guided focusing helps identify and prioritize the most relevant contexts for answering.}
\label{fig:visual}
\end{figure}